ImageNet training time: 257.459 (no validation)
training schedule: [1, 1]
#!/bin/bash

# count unique ranks
jobs &>/dev/null
echo &
new_job_started="$(jobs -n)"
if [ -n "$new_job_started" ];then
    PID=$!
else
    PID=
fi

# distributed strategy
if [ "$STRATEGY" == "multi_worker_mirrored" ]
then 
  MULTI_WORKER_FLAGS="--use_train_and_evaluate --all_reduce_alg=nccl"
else
  MULTI_WORKER_FLAGS=""
fi 
# Hyperparameters tuned at scale (1024 nodes)
export HOROVOD_HIERARCHICAL_ALLGATHER=0
export HOROVOD_HIERARCHICAL_ALLREDUCE=0
export HOROVOD_GROUPED_ALLREDUCES=1
export HOROVOD_CYCLE_TIME=1
export HOROVOD_FUSION_THRESHOLD=8388608

# results directory to store .qdrep
RUN=j_${LSB_JOBID}
RES_DIR=profiling_results/${NODES}_nodes/$RUN
if [ $PMIX_RANK -eq 0 ]
then
    mkdir -p $RES_DIR
fi
PROF_FILE=$DATADIR/nsys.${LSB_JOBID}.r${PID}.w${LSB_JOB_NUMPROC}

if [ "$DATA_MODE" == "real" ]
then 
    #Real data benchmarking (convergence testing)
    #nvprof -o $PROF_FILE python -u ./official/resnet/imagenet_main.py \
    #nsys profile -o $PROF_FILE -t cuda,nvtx,mpi,osrt --mpi-impl=openmpi \
    nsys profile -o $PROF_FILE -t cuda \
	python -u ./official/resnet/imagenet_main.py \
        --clean \
        --distribution_strategy=$STRATEGY \
        $MULTI_WORKER_FLAGS \
        --data_dir=$DATADIR \
        --label_smoothing=0 \
        --train_epochs=2 \
        --batch_size=128 \
        --enable_lars \
        --fp16_implementation=casting \
        --dtype=fp16 \
        --inter_op_parallelism_threads=4 \
        --intra_op_parallelism_threads=7 \
        --tf_gpu_thread_mode=gpu_private \
        --per_gpu_thread_count=4 \
        --hooks=ExamplesPerSecondHook,LoggingTensorHook \
        --model_dir=$MODELDIR 2>&1 > /mnt/bb/$USER/log.${LSB_JOBID}

    cp $PROF_FILE.qdrep $RES_DIR
else
    # Synthetic data benchmarking (images/sec with batch size = 128)
    nsys profile -o $PROF_FILE -t cuda \
         python -u ./official/resnet/imagenet_main.py \
         --clean \
         --distribution_strategy=$STRATEGY \
         $MULTI_WORKER_FLAGS \
         --use_synthetic_data \
         --train_epochs=2 \
         --batch_size=128 \
         --enable_lars \
         --fp16_implementation=casting \
         --dtype=fp16 \
         --inter_op_parallelism_threads=4 \
         --intra_op_parallelism_threads=7 \
         --tf_gpu_thread_mode=gpu_private \
         --per_gpu_thread_count=4 \
         --hooks=ExamplesPerSecondHook,LoggingTensorHook \
         --model_dir=$MODELDIR 2>&1 > /mnt/bb/$USER/log.${LSB_JOBID}
    
    cp $PROF_FILE.qdrep $RES_DIR
fi

if [ $PMIX_RANK -eq 0 ]
then
    cp /mnt/bb/$USER/log.${LSB_JOBID} .
fi

